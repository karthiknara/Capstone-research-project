{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDqiK1IsaQne",
        "outputId": "116a5462-b9e5-4fb4-8e18-7dc37c2947e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycurl\n",
            "  Downloading pycurl-7.45.2.tar.gz (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.2/234.2 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycurl\n",
            "  Building wheel for pycurl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycurl: filename=pycurl-7.45.2-cp38-cp38-linux_x86_64.whl size=341425 sha256=2a296f503bfd9ae5b2f347a35edbe90337a9b1bdace3c1726ced5afdf82cc0f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/65/79/9497b682fcb877281b1600e6580f5a9627bed14d29c361ecaa\n",
            "Successfully built pycurl\n",
            "Installing collected packages: pycurl\n",
            "Successfully installed pycurl-7.45.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycurl\n",
        "!pip install certifi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIzZVvBcia6S",
        "outputId": "d3b4d696-c1e4-43de-8dc6-4dda605042e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "tyGZkeI_70ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "def unhtml(string):\n",
        "    # replace <tag>...</tag>, possibly more than once\n",
        "    done = False\n",
        "    while not done:\n",
        "        temp = re.sub(r'<([^/]\\S*)[^>]*>[\\s\\S]*?</\\1>', '', string)\n",
        "        done = temp == string\n",
        "        string = temp\n",
        "    # replace remaining standalone tags, if any\n",
        "    string = re.sub(r'<[^>]*>', '', string)\n",
        "    string = re.sub(r'\\s{2,}', ' ', string)\n",
        "    return string.strip()\n",
        "\n",
        "def cleanup(element):\n",
        "    if isinstance(element, list):\n",
        "        for i, item in enumerate(element):\n",
        "            element[i] = cleanup(item)\n",
        "    elif isinstance(element, dict):\n",
        "        for key in element.keys():\n",
        "            element[key] = cleanup(element[key])\n",
        "    elif isinstance(element, str):\n",
        "        element = unhtml(element)\n",
        "\n",
        "    return element"
      ],
      "metadata": {
        "id": "jiJTLrAo6E0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# assign directory\n",
        "old_directory = '/content/drive/MyDrive/courtlistener_html'\n",
        " \n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.listdir(old_directory):\n",
        "  f = os.path.join(old_directory, filename)\n",
        "  # json_string = open(f)\n",
        "  # checking if it is a file\n",
        "  with open(f, \"r\") as content:\n",
        "    # print(json.loads(f.read()))\n",
        "    data = json.loads(content.read())\n",
        "    cleanup(data)\n",
        "    json_string = json.dumps(data)\n",
        "    new_directory = '/content/drive/MyDrive/courtlistener_nohtml'\n",
        "    g = os.path.join(new_directory, filename)\n",
        "    with open(g, 'w') as outfile:\n",
        "      outfile.write(json_string)"
      ],
      "metadata": {
        "id": "p2djCbu8Bnpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "p1IjHC2NL4CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(text):\n",
        "    \"\"\"Remove html tags from a string\"\"\"\n",
        "    import re\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)"
      ],
      "metadata": {
        "id": "IuAXykA4TsPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(d):\n",
        "    if isinstance(d, dict):\n",
        "        for v in d.values():\n",
        "            yield from flatten(v)\n",
        "    elif isinstance(d, list):\n",
        "        for v in d:\n",
        "            yield from flatten(v)\n",
        "    elif isinstance(d, str):\n",
        "        yield d"
      ],
      "metadata": {
        "id": "Ynv7MA-3XFpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_tags(html):\n",
        " \n",
        "    # parse html content\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        " \n",
        "    for data in soup(['style', 'script']):\n",
        "        # Remove tags\n",
        "        data.decompose()\n",
        " \n",
        "    # return data by retrieving the tag content\n",
        "    return ' '.join(soup.stripped_strings)"
      ],
      "metadata": {
        "id": "L7MXn6F9Xsnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "EQ1nvzW5d7pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_directory = '/content/drive/MyDrive/courtlistener_html'\n",
        "\n",
        "for filename in os.listdir(old_directory):\n",
        "  f = os.path.join(old_directory, filename)\n",
        "  # json_string = open(f)\n",
        "  # checking if it is a file\n",
        "  # with open(f, \"r\") as content:\n",
        "  with open(f, 'r', encoding = 'utf-8') as load_file:\n",
        "    content = load_file.read()\n",
        "    soup = BeautifulSoup(content)\n",
        "    text = soup.get_text()\n",
        "    # invalid_tags = ['\\r', '\\n', '\\\\n', '\\\\u201d', '\\\\u201c', '\\u2019', '\\u2014']\n",
        "    # for invalid_tag in invalid_tags:\n",
        "    #   text = text.replace(invalid_tag, '')\n",
        "    text = text.replace('xml_harvard', 'opinion')\n",
        "    # json_string = json.dumps(text)\n",
        "    new_directory = '/content/drive/MyDrive/courtlistener_nohtml_7'\n",
        "    g = os.path.join(new_directory, filename)\n",
        "    with open(g, 'w') as outfile:\n",
        "      outfile.write(text)"
      ],
      "metadata": {
        "id": "Q9FtRF4sL4da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "old_directory = '/content/drive/MyDrive/courtlistener_nohtml_7'\n",
        "merged_json_data = []\n",
        "\n",
        "for filename in os.listdir(old_directory):\n",
        "  f = os.path.join(old_directory, filename)\n",
        "  # json_string = open(f)\n",
        "  # checking if it is a file\n",
        "  # with open(f, \"r\") as content:\n",
        "  with open(f, 'r', encoding = 'utf-8') as load_file:\n",
        "    # content = load_file.read()\n",
        "    json_data = json.load(load_file)\n",
        "    res_1 = {key: json_data[key] for key in json_data.keys()\n",
        "       & {'id', 'syllabus'}}\n",
        "    res_2 = {key: json_data[key] for key in json_data.keys()\n",
        "       & {'sub_opinions'}}\n",
        "    res_3 = {key: json_data[key] for key in json_data.keys()\n",
        "       & {'docket'}}\n",
        "    values_1 = res_2['sub_opinions']\n",
        "    values_2 = res_3['docket']\n",
        "    opinion = values_1[0]['opinion']\n",
        "    # print(res_3)\n",
        "    docket_number = values_2['docket_number']\n",
        "    res_3 = dict({'docket_number': docket_number})\n",
        "    res_4 = dict({'opinion': opinion})\n",
        "    res_1.update(res_3)\n",
        "    res_1.update(res_4)\n",
        "    merged_json_data.append(res_1)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/mergedjson5.json\", \"w\") as outfile:\n",
        "  json.dump(merged_json_data, outfile)"
      ],
      "metadata": {
        "id": "JFyW8a7IOSGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/supremecourtdataset_1324casestotal.json', encoding='utf-8') as data_file:\n",
        "   data = json.loads(data_file.read())"
      ],
      "metadata": {
        "id": "ROuyTeoniEJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/supremecourtdataset_1324casestotal.json', encoding='utf-8') as data_file:\n",
        "   new_data = json.loads(data_file.read())"
      ],
      "metadata": {
        "id": "blmPeV613trM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_copy = data"
      ],
      "metadata": {
        "id": "1GytrnT_3aOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofkst51fiq0F",
        "outputId": "8b3c6349-acf1-41fe-bf96-9e2f6d794494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1324"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiwXs9T0jNRl",
        "outputId": "16b811f0-6f3b-4771-9f3f-736d0ce18422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_sentences = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  opinion_text = data[i][\"opinion\"]\n",
        "  opinion_text_token = sent_tokenize(opinion_text)\n",
        "  number_of_sentences.append(len(opinion_text_token))"
      ],
      "metadata": {
        "id": "iJnbvGORjOfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del new_data"
      ],
      "metadata": {
        "id": "j-vh6dYZ40pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = []\n",
        "\n",
        "for i in range(len(number_of_sentences)):\n",
        "  if number_of_sentences[i] > 2:\n",
        "    new_data.append(data[i])"
      ],
      "metadata": {
        "id": "N3Cwc1dhjla1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mna8gB8P47Sz",
        "outputId": "77b22360-a75b-40ef-c889-e7dda6e0d5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "717"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/supremecourtdataset_717totalcases.json\", \"w\") as outfile:\n",
        "  json.dump(new_data, outfile)"
      ],
      "metadata": {
        "id": "invjx8H-4_ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geBI5uUy55q7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}